{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loss functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83b5ff4a40705d2"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT_DIR = Path('..') / '..'\n",
    "!pip install -q -r {ROOT_DIR / 'requirements.txt'}\n",
    "\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.779780300Z",
     "start_time": "2023-08-19T04:53:15.746402600Z"
    }
   },
   "id": "142a7754c54dcec7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross entropy loss\n",
    "\n",
    "$$H(p, q) = - \\sum_{x \\in X} p(x) log(q(x))$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afd2e68224b82a87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Examples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c26debeb0fa2a024"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from loss import cross_entropy, binary_cross_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.787139600Z",
     "start_time": "2023-08-19T04:53:17.781625600Z"
    }
   },
   "id": "54a4691ecefdcc57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Simple Binary Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68c549bfd6b0ec02"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0821)\n"
     ]
    }
   ],
   "source": [
    "# Example predictions for binary classification\n",
    "predictions = torch.tensor([0.9, 0.3, 0.2, 0.8])\n",
    "\n",
    "# Corresponding ground truth labels (either 0 or 1)\n",
    "targets = torch.tensor([1, 0, 0, 1])\n",
    "\n",
    "loss = cross_entropy(predictions, targets)\n",
    "print(loss) # tensor(0.0821)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.798062100Z",
     "start_time": "2023-08-19T04:53:17.785141800Z"
    }
   },
   "id": "587480de4a874464"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Multi-class Classification\n",
    "\n",
    "For multi-class classification problems, the cross entropy function should be used with softmax outputs. Here's a simplified example:#"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16601d92eb8cfd98"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1035)\n"
     ]
    }
   ],
   "source": [
    "from activations import softmax\n",
    "\n",
    "# Mock predictions from a network (logits)\n",
    "logits = torch.tensor([[2.0, 1.0, 0.1], [0.5, 2.5, 0.1]])\n",
    "\n",
    "# Convert logits to probabilities\n",
    "predictions = softmax(logits, dim=1)\n",
    "\n",
    "# Ground truth in one-hot encoded format\n",
    "targets = torch.tensor([[1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "loss = cross_entropy(predictions, targets)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.843765500Z",
     "start_time": "2023-08-19T04:53:17.797060400Z"
    }
   },
   "id": "71568d76fa7a094f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Using the Stable Version\n",
    "\n",
    "As with the softmax function, numerical instability can sometimes be an issue when dealing with very small or very large values. Here's how to use the stable version:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90c42c6172caff74"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0264)\n"
     ]
    }
   ],
   "source": [
    "# Some mock predictions\n",
    "predictions = torch.tensor([0.9999, 0.0001, 0.9, 0.1])\n",
    "\n",
    "# Corresponding ground truth\n",
    "targets = torch.tensor([1, 0, 1, 0])\n",
    "\n",
    "loss = cross_entropy(predictions, targets, stable=True)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.844765900Z",
     "start_time": "2023-08-19T04:53:17.806773Z"
    }
   },
   "id": "bd0762125773bc27"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Avoiding Zero Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "832d0d6da4b2b28a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `eps` parameter helps to avoid taking the logarithm of zero:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "817ec4c65a139652"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0263)\n"
     ]
    }
   ],
   "source": [
    "# Mock predictions with a zero\n",
    "predictions = torch.Tensor([1.0, 0.0, 0.9, 0.2])\n",
    "\n",
    "# Corresponding ground truth\n",
    "targets = torch.Tensor([1, 0, 1, 0])\n",
    "\n",
    "# Using an epsilon value\n",
    "loss = cross_entropy(predictions, targets, stable=True, eps=1e-8)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.844765900Z",
     "start_time": "2023-08-19T04:53:17.817772300Z"
    }
   },
   "id": "a1b3e24417e7aa2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. Dealing with Batches\n",
    "\n",
    "Typically, when training neural networks, we process inputs in batches. The function can handle batched inputs seamlessly:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2361c094edb6c317"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1142)\n"
     ]
    }
   ],
   "source": [
    "# Batched predictions\n",
    "predictions = torch.Tensor([[0.9, 0.1], [0.7, 0.3], [0.2, 0.8]])\n",
    "\n",
    "# Batched targets\n",
    "targets = torch.Tensor([[1, 0], [1, 0], [0, 1]])\n",
    "\n",
    "loss = cross_entropy(predictions, targets)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.845766600Z",
     "start_time": "2023-08-19T04:53:17.824372100Z"
    }
   },
   "id": "7e3cc9baa4b1b32a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binary Cross Entropy Loss\n",
    "\n",
    "$$H(p, q) = - \\sum_{x \\in X} p(x) log(q(x)) + (1 - p(x)) log(1 - q(x))$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f88079c403acd4cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Examples\n",
    "\n",
    "Binary cross entropy loss, often used in binary classification problems, quantifies the difference between two probability distributions: the true labels and the predicted probabilities. Let's see it in action:\n",
    "\n",
    "#### 1. Basic Binary Classification:\n",
    "\n",
    "Here's a straightforward use of binary cross entropy for a single prediction."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d42810fd7ac4948d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2271)\n"
     ]
    }
   ],
   "source": [
    "# Mock predictions for binary classification\n",
    "predictions = torch.Tensor([0.9, 0.3, 0.2, 0.8])\n",
    "\n",
    "# Corresponding ground truth labels (either 0 or 1)\n",
    "targets = torch.Tensor([1, 0, 0, 1])\n",
    "\n",
    "loss = binary_cross_entropy(predictions, targets)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.845766600Z",
     "start_time": "2023-08-19T04:53:17.836927100Z"
    }
   },
   "id": "e037049ba97f66df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Stable Version Usage:\n",
    "\n",
    "It's often good to use the stable version of the binary cross entropy to avoid numerical instabilities:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1413e0a0216a6085"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0527)\n"
     ]
    }
   ],
   "source": [
    "# Some mock predictions\n",
    "predictions = torch.Tensor([0.9999, 0.0001, 0.9, 0.1])\n",
    "\n",
    "# Corresponding ground truth\n",
    "targets = torch.Tensor([1, 0, 1, 0])\n",
    "\n",
    "loss = binary_cross_entropy(predictions, targets, stable=True)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.856446300Z",
     "start_time": "2023-08-19T04:53:17.844765900Z"
    }
   },
   "id": "3f2d1c57271c706a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Dealing with Close-to-Zero or One Predictions:\n",
    "\n",
    "When predictions are very close to `0` or `1`, the logarithm can cause problems. The `eps` parameter can help:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59e5ea533533e455"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0005)\n"
     ]
    }
   ],
   "source": [
    "# Mock predictions with values close to 0 and 1\n",
    "predictions = torch.Tensor([1.0, 0.0, 0.999, 0.001])\n",
    "\n",
    "# Corresponding ground truth\n",
    "targets = torch.Tensor([1, 0, 1, 0])\n",
    "\n",
    "# Using the epsilon parameter for stability\n",
    "loss = binary_cross_entropy(predictions, targets, stable=True, eps=1e-6)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:53.001279600Z",
     "start_time": "2023-08-19T04:53:52.993419800Z"
    }
   },
   "id": "338f07adeea8dff7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Batches of Predictions:\n",
    "\n",
    "The function is designed to handle batches of inputs:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f453916adc6a455"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2284)\n"
     ]
    }
   ],
   "source": [
    "# Batched predictions\n",
    "predictions = torch.Tensor([[0.9], [0.7], [0.2]])\n",
    "\n",
    "# Batched targets\n",
    "targets = torch.Tensor([[1], [1], [0]])\n",
    "\n",
    "loss = binary_cross_entropy(predictions, targets)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:53:17.945476500Z",
     "start_time": "2023-08-19T04:53:17.868446100Z"
    }
   },
   "id": "af3012a149e8c33e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
